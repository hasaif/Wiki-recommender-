{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SparkFiles\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import split, col, struct, udf\n",
    "from pyspark.sql import Row\n",
    "import sys\n",
    "#import google_compute_engine\n",
    "import gensim\n",
    "from gensim import corpora,models,similarities\n",
    "from gensim.matutils import softcossim \n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"Final\")\n",
    "sc = SparkContext(conf = conf)\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## load word embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addFile(\"gs://wiki_final/subword.vec\")\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(SparkFiles.get(\"subword.vec\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load wiki dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xml = spark.read.format('xml').options(rowTag=\"page\").load('gs://wiki_final/big_data.xml.bz2')\n",
    "xml = spark.read.format('xml').options(rowTag=\"page\").load('gs://wiki_final/Wikipedia-test-SUBSET.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used in map function\n",
    "def getText(row):\n",
    "        #complex struct structure to get text field \n",
    "        s = row.revision.text._VALUE\n",
    "        #return text a id(used for join)\n",
    "        return   Row(title =row.title, text= prepText(s) ,id_= row.id)\n",
    "\n",
    "def prepText(s):\n",
    "        punc='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n'\n",
    "        lowercased_str = str(s).lower()\n",
    "        for ch in punc:\n",
    "            lowercased_str = lowercased_str.replace(ch, ' ')\n",
    "        return rmSp(lowercased_str.split(' '))\n",
    "                            \n",
    "def rmSp(x):\n",
    "        r = []\n",
    "        for w in x:\n",
    "            if w!='':\n",
    "                r.append(w)\n",
    "        return r\n",
    "\n",
    "#df -> rdd to transform the data into sql Rows and make text array\n",
    "textRDD = xml.select('revision', 'id', 'title').rdd.map(getText)#makes a DF with text and ID \n",
    "#back to df to strip stopwords \n",
    "t = textRDD.toDF()\n",
    "remover = StopWordsRemover(inputCol=\"text\", outputCol=\"filtered\")\n",
    "stop_removed =  remover.transform(t)\n",
    "\n",
    "#New data with id_, title, text, filtered\n",
    "stop_removed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dictionary\n",
    "## create similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = corpora.Dictionary(stop_removed.select('filtered').rdd.map(lambda x: x.filtered).collect())\n",
    "similarity_matrix = model.similarity_matrix(dt, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "print(\"similarity mat created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert articles to bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dt = stop_removed.select('filtered','id_').rdd.map(lambda x:Row(id_ = x.id_, text =  dt.doc2bow(x.filtered)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for each article:\n",
    "* calculate cosine similarities\n",
    "* sort similarities\n",
    "* save top 10 similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.emptyRDD()\n",
    "for article in sent_dt.collect():\n",
    "        recs = sent_dt.map(lambda x:Row(id_ = x.id_, cos =softcossim(article.text, x.text, similarity_matrix))).sortBy(lambda x: x.cos, ascending=False).take(10) \n",
    "        # this will caclulate top 10 similarities \n",
    "        rdd2 = sc.parallelize(Row(id_ = article.id_,recs = recs))\n",
    "        rdd1 = rdd1.union(rdd2)\n",
    "\n",
    "        #save results RDD to Bucket\n",
    "rdd1.saveAsTextFile(\"gs://wiki_final/rec_id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
